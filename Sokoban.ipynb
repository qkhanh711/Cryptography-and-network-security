{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sokoban():\n",
    "    def __init__(self, level):\n",
    "        self.level = level\n",
    "        self.player = None\n",
    "        self.walls = []\n",
    "        self.boxes = []\n",
    "        self.goals = []\n",
    "        self.load_level(level)\n",
    "        self.state = self.get_state()\n",
    "        self.action_space = ['u', 'd', 'l', 'r']\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.observation_space = self.get_state().shape\n",
    "\n",
    "    def load_level(self, level):\n",
    "        with open(level) as f:\n",
    "            lines = f.readlines()\n",
    "        for y, line in enumerate(lines):\n",
    "            for x, char in enumerate(line):\n",
    "                if char == '#':\n",
    "                    self.walls.append((x, y))\n",
    "                elif char == '@':\n",
    "                    self.boxes.append((x, y))\n",
    "                elif char == '+':\n",
    "                    self.boxes.append((x, y))\n",
    "                    self.player = (x, y)\n",
    "                elif char == '.':\n",
    "                    self.goals.append((x, y))\n",
    "                elif char == '*':\n",
    "                    self.goals.append((x, y))\n",
    "                    self.boxes.append((x, y))\n",
    "                elif char == ' ':\n",
    "                    pass\n",
    "                else:\n",
    "                    raise Exception('Invalid character %s at %s' % (char, (x, y)))\n",
    "\n",
    "    def get_state(self):\n",
    "        state = np.zeros((len(self.walls), 3), dtype=np.float32)\n",
    "        for i, wall in enumerate(self.walls):\n",
    "            state[i, 0] = wall[0] / 10\n",
    "            state[i, 1] = wall[1] / 10\n",
    "            state[i, 2] = 1\n",
    "        for i, box in enumerate(self.boxes):\n",
    "            state[i + len(self.walls), 0] = box[0] / 10\n",
    "            state[i + len(self.walls), 1] = box[1] / 10\n",
    "            state[i + len(self.walls), 2] = 2\n",
    "        state[len(self.walls) + len(self.boxes), 0] = self.player[0] / 10\n",
    "        state[len(self.walls) + len(self.boxes), 1] = self.player[1] / 10\n",
    "        state[len(self.walls) + len(self.boxes), 2] = 3\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        if action=='u':\n",
    "            new_player = (self.player[0], self.player[1] - 1)\n",
    "        elif action=='d':\n",
    "            new_player = (self.player[0], self.player[1] + 1)\n",
    "        elif action=='l':\n",
    "            new_player = (self.player[0] - 1, self.player[1])\n",
    "        elif action=='r':\n",
    "            new_player = (self.player[0] + 1, self.player[1])\n",
    "        else:\n",
    "            raise Exception('Invalid action %s' % action)\n",
    "        if new_player in self.walls:\n",
    "            return -1, False\n",
    "        if new_player in self.boxes:\n",
    "            new_box = (new_player[0] + (new_player[0] - self.player[0]), new_player[1] + (new_player[1] - self.player[1]))\n",
    "            if new_box in self.walls or new_box in self.boxes:\n",
    "                return -1, False\n",
    "            self.boxes.remove(new_player)\n",
    "            self.boxes.append(new_box)\n",
    "        self.player = new_player\n",
    "        return self.get_reward(), self.is_done()\n",
    "    \n",
    "    def get_reward(self):\n",
    "        reward = 0\n",
    "        for box in self.boxes:\n",
    "            if box in self.goals:\n",
    "                reward += 1\n",
    "        return reward\n",
    "    \n",
    "    def is_done(self):\n",
    "        for box in self.boxes:\n",
    "            if box not in self.goals:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__(self.level)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def render(self):\n",
    "        for y in range(10):\n",
    "            for x in range(10):\n",
    "                if (x, y) in self.walls:\n",
    "                    print('#', end='')\n",
    "                elif (x, y) in self.boxes:\n",
    "                    if (x, y) in self.goals:\n",
    "                        print('*', end='')\n",
    "                    else:\n",
    "                        print('@', end='')\n",
    "                elif (x, y) == self.player:\n",
    "                    if (x, y) in self.goals:\n",
    "                        print('+', end='')\n",
    "                    else:\n",
    "                        print('.', end='')\n",
    "                elif (x, y) in self.goals:\n",
    "                    print('.', end='')\n",
    "                else:\n",
    "                    print(' ', end='')\n",
    "            print()\n",
    "        print()\n",
    "\n",
    "# Path: Sokoban.ipynb\n",
    "def get_action(state, model, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return np.random.randint(0, 4)\n",
    "    else:\n",
    "        q_values = model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "    \n",
    "# Path: Sokoban.ipynb\n",
    "\n",
    "def train_model(model, target_model, memory, batch_size, gamma):\n",
    "    if len(memory) < batch_size * 3:\n",
    "        return\n",
    "    batch = random.sample(memory, batch_size)\n",
    "    states = np.array([val[0] for val in batch])\n",
    "    actions = np.array([val[1] for val in batch])\n",
    "    rewards = np.array([val[2] for val in batch])\n",
    "    next_states = np.array([val[3] for val in batch])\n",
    "    dones = np.array([val[4] for val in batch])\n",
    "    states = np.squeeze(states)\n",
    "    next_states = np.squeeze(next_states)\n",
    "    q_values = model.predict(states)\n",
    "    next_q_values = target_model.predict(next_states)\n",
    "    for i in range(len(batch)):\n",
    "        if dones[i]:\n",
    "            q_values[i, actions[i]] = rewards[i]\n",
    "        else:\n",
    "            q_values[i, actions[i]] = rewards[i] + gamma * np.max(next_q_values[i])\n",
    "    model.fit(states, q_values, verbose=0)\n",
    "\n",
    "# Path: Sokoban.ipynb\n",
    "\n",
    "def play(model, target_model, memory, epsilon, epsilon_decay, epsilon_min, batch_size, gamma):\n",
    "    env = Sokoban('levels/level1.txt')\n",
    "    done = False\n",
    "    steps = 0\n",
    "    state = env.get_state()\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        action = get_action(state, model, epsilon)\n",
    "        reward, done = env.step(env.action_space[action])\n",
    "        next_state = env.get_state()\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        train_model(model, target_model, memory, batch_size, gamma)\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "    return steps\n",
    "\n",
    "# Path: Sokoban.ipynb\n",
    "\n",
    "def test(model):\n",
    "    env = Sokoban('levels/level1.txt')\n",
    "    done = False\n",
    "    steps = 0\n",
    "    state = env.get_state()\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        action = get_action(state, model, 0)\n",
    "        reward, done = env.step(env.action_space[action])\n",
    "        state = env.get_state()\n",
    "    return steps\n",
    "\n",
    "# Path: Sokoban.ipynb\n",
    "\n",
    "def main():\n",
    "    memory = deque(maxlen=100000)\n",
    "    gamma = 0.95\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    epsilon_min = 0.01\n",
    "    batch_size = 64\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(len(Sokoban('levels/level1.txt').get_state().flatten()),), activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "    target_model = Sequential()\n",
    "    target_model.add(Dense(128, input_shape=(len(Sokoban('levels/level1.txt').get_state().flatten()),), activation='relu'))\n",
    "    target_model.add(Dense(128, activation='relu'))\n",
    "    target_model.add(Dense(4, activation='linear'))\n",
    "    target_model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "    target_model.set_weights(model.get_weights())\n",
    "    for i in range(1000):\n",
    "        steps = play(model, target_model, memory, epsilon, epsilon_decay, epsilon_min, batch_size, gamma)\n",
    "        print('Episode: %s, Steps: %s, Epsilon: %s' % (i, steps, epsilon))\n",
    "        if i % 10 == 0:\n",
    "            target_model.set_weights(model.get_weights())\n",
    "    print('Testing...')\n",
    "    steps = test(model)\n",
    "    print('Steps: %s' % steps)\n",
    "\n",
    "# Path: Sokoban.ipynb\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
